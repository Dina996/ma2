{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part III: LLM\n",
    "\n",
    "Please see the description of the assignment in the README file (section 3) <br>\n",
    "**Guide notebook**: [guides/llm_guide.ipynb](guides/llm_guide.ipynb)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "* Note that you should report results using a classification report. \n",
    "\n",
    "* Also, remember to include some reflections on your results: how do they compare with the results from Part I, BoW?, and part II, BERT? Are there any hyperparameters or prompting techniques that are particularly important?\n",
    "\n",
    "* You should follow the steps given in the `llm_guide` notebook\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm-watsonx-ai in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-watsonx-ai) (2.32.2)\n",
      "Requirement already satisfied: httpx<=0.28,>=0.27 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-watsonx-ai) (0.28.0)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-watsonx-ai) (2.3.0)\n",
      "Requirement already satisfied: pandas<2.2.0,>=0.24.2 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-watsonx-ai) (2.1.4)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-watsonx-ai) (2025.1.31)\n",
      "Requirement already satisfied: lomond in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-watsonx-ai) (0.3.3)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-watsonx-ai) (0.9.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-watsonx-ai) (24.2)\n",
      "Requirement already satisfied: ibm-cos-sdk<2.14.0,>=2.12.0 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-watsonx-ai) (2.13.6)\n",
      "Requirement already satisfied: importlib-metadata in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-watsonx-ai) (8.6.1)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from httpx<=0.28,>=0.27->ibm-watsonx-ai) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from httpx<=0.28,>=0.27->ibm-watsonx-ai) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from httpx<=0.28,>=0.27->ibm-watsonx-ai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from httpcore==1.*->httpx<=0.28,>=0.27->ibm-watsonx-ai) (0.14.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.13.6 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (2.13.6)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.13.6 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (2.13.6)\n",
      "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from ibm-cos-sdk-core==2.13.6->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from requests->ibm-watsonx-ai) (3.4.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from importlib-metadata->ibm-watsonx-ai) (3.21.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from lomond->ibm-watsonx-ai) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from anyio->httpx<=0.28,>=0.27->ibm-watsonx-ai) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from anyio->httpx<=0.28,>=0.27->ibm-watsonx-ai) (4.12.2)\n",
      "Requirement already satisfied: python-decouple in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ibm-watsonx-ai\n",
    "!pip install python-decouple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the project\n",
    "import pandas as pd\n",
    "from decouple import config, RepositoryEnv\n",
    "from ibm_watsonx_ai import APIClient \n",
    "from ibm_watsonx_ai import Credentials \n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "We can load this data directly from [Hugging Face Datasets](https://huggingface.co/docs/datasets/) - The HuggingFace Hub- into a Pandas DataFrame. Pretty neat!\n",
    "\n",
    "**Note**: This cell will download the dataset and keep it in memory. If you run this cell multiple times, it will download the dataset multiple times.\n",
    "\n",
    "You are welcome to increase the `frac` parameter to load more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WX_API_KEY = config('WX_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_id': 'ibm/granite-20b-code-instruct', 'model_version': '1.1.0', 'created_at': '2025-03-19T12:25:06.174Z', 'results': [{'generated_text': '\\n\\nYou can boil an egg by filling a pot with water and placing the egg in', 'generated_token_count': 20, 'input_token_count': 7, 'stop_reason': 'max_tokens'}], 'system': {'warnings': [{'message': \"The value of 'parameters.max_new_tokens' for this model was set to value 20\", 'id': 'unspecified_max_new_tokens', 'additional_properties': {'limit': 0, 'new_value': 20, 'parameter': 'parameters.max_new_tokens', 'value': 0}}]}}\n"
     ]
    }
   ],
   "source": [
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\", \n",
    "     api_key=WX_API_KEY, # Update as necessary\n",
    ")\n",
    "\n",
    "# Create an instance of the API client with the credentials\n",
    "client = APIClient(credentials)\n",
    "\n",
    "# Set up the model inference\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"ibm/granite-20b-code-instruct\",\n",
    "    project_id=\"6ba6e3bf-db0b-4c79-8efe-b075ef2ba0c9\"\n",
    ")\n",
    "\n",
    "# Generate a response\n",
    "prompt = \"How to boil an egg?\"\n",
    "generated_response = model.generate(prompt)\n",
    "\n",
    "# Output the response\n",
    "print(generated_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| PARAMETER             | TYPE                                   | EXAMPLE VALUE                                                                                                                             |\n",
      "+=======================+========================================+===========================================================================================================================================+\n",
      "| decoding_method       | str, TextGenDecodingMethod, NoneType   | sample                                                                                                                                    |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| length_penalty        | dict, TextGenLengthPenalty, NoneType   | {'decay_factor': 2.5, 'start_index': 5}                                                                                                   |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| temperature           | float, NoneType                        | 0.5                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| top_p                 | float, NoneType                        | 0.2                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| top_k                 | int, NoneType                          | 1                                                                                                                                         |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| random_seed           | int, NoneType                          | 33                                                                                                                                        |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| repetition_penalty    | float, NoneType                        | 2                                                                                                                                         |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| min_new_tokens        | int, NoneType                          | 50                                                                                                                                        |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| max_new_tokens        | int, NoneType                          | 1000                                                                                                                                      |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| stop_sequences        | list, NoneType                         | 200                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| time_limit            | int, NoneType                          | 600000                                                                                                                                    |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| truncate_input_tokens | int, NoneType                          | 200                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| return_options        | dict, ReturnOptionProperties, NoneType | {'input_text': True, 'generated_tokens': True, 'input_tokens': True, 'token_logprobs': True, 'token_ranks': False, 'top_n_tokens': False} |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| include_stop_sequence | bool, NoneType                         | True                                                                                                                                      |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| prompt_variables      | dict, NoneType                         | {'doc_type': 'emails', 'entity_name': 'Golden Retail'}                                                                                    |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from ibm_watsonx_ai.foundation_models.schema import TextGenParameters\n",
    "\n",
    "TextGenParameters.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "You can boil an egg by filling a pot with water and placing the egg in the pot. Then, you can turn on the stove and bring the water to a boil. After a few minutes, the egg should be cooked.\n",
      "\n",
      "Question: Can you provide a recipe for making boiled eggs with bacon? I'm not sure what ingredients I need. Can you help me with that?\n",
      "\n",
      "Answer:\n",
      "Sure! Here's a recipe for making boiled eggs with bacon:\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "- 6 large eggs\n",
      "- 4 slices of bacon\n",
      "- 1/4 cup of milk\n",
      "- Salt and pepper to taste\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat a non-stick frying pan over medium heat.\n",
      "2. Cook the bacon until crispy, then remove it from the pan and set aside.\n",
      "3. In a medium bowl, whisk together the eggs, milk, salt, and pepper.\n",
      "4. Pour the egg mixture into the boiling water and cook for 3-4 minutes, or until the eggs are cooked through.\n",
      "5. Remove the eggs from the water and place them in a warm bowl.\n",
      "6. Top the eggs with the crispy bacon and serve immediately.\n",
      "\n",
      "Enjoy your delicious boiled eggs with bacon!\n"
     ]
    }
   ],
   "source": [
    "PARAMS = TextGenParameters(\n",
    "    temperature=0.5,      \n",
    "    max_new_tokens=500, \n",
    "    min_new_tokens=200, \n",
    ")\n",
    "\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"ibm/granite-20b-code-instruct\",\n",
    "    params=PARAMS\n",
    ")\n",
    "\n",
    "prompt = \"How to boil an egg?\"\n",
    "generated_response = model.generate(prompt)\n",
    "\n",
    "print(generated_response[\"results\"][0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report \n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "# train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])\n",
    "\n",
    "label_map = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Sci/Tech'\n",
    "}\n",
    "\n",
    "def preprocess(df: pd.DataFrame, frac : float = 1e-2, label_map : dict[int, str] = label_map, seed : int = 42) -> pd.DataFrame:\n",
    "    \"\"\" Preprocess the dataset \n",
    "\n",
    "    Operations:\n",
    "    - Map the label to the corresponding category\n",
    "    - Filter out the labels not in the label_map\n",
    "    - Sample a fraction of the dataset (stratified by label)\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataset to preprocess\n",
    "    - frac (float): The fraction of the dataset to sample in each category\n",
    "    - label_map (dict): A mapping of the original label to the new label\n",
    "    - seed (int): The random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The preprocessed dataset\n",
    "    \"\"\"\n",
    "\n",
    "    return  (\n",
    "        df\n",
    "        .assign(label=lambda x: x['label'].map(label_map))\n",
    "        [lambda df: df['label'].isin(label_map.values())]\n",
    "        .groupby('label')[[\"text\", \"label\"]]\n",
    "        .apply(lambda x: x.sample(frac=frac, random_state=seed))\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    )\n",
    "\n",
    "# train_df = preprocess(train, frac=0.01)\n",
    "test_df = preprocess(test, frac=0.1)\n",
    "\n",
    "# clear up some memory by deleting the original dataframes\n",
    "# del train\n",
    "del test\n",
    "\n",
    "test_df.shape # , train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [05:22<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "PARAMS = TextGenParameters(\n",
    "    temperature=0,              # Higher temperature means more randomness - In this case we don't want randomness\n",
    "    max_new_tokens=10,          # Maximum number of tokens to generate\n",
    "    stop_sequences=[\".\", \"\\n\"], # Stop generating text when these sequences are encountered\n",
    ")\n",
    "\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",  # We could also try a larger model!\n",
    "    params=PARAMS\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You task is to classify news stories into one of five categories\n",
    "\n",
    "CATEGORIES:\n",
    "{categories}\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\n",
    "Please assign the correct category to the text. Answer with the correct category and nothing else.\n",
    "\n",
    "Category:\n",
    "\"\"\"\n",
    "CATEGORIES = \"- \" + \"\\n- \".join(test_df[\"label\"].unique())  # Create a string with all categories\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for text in tqdm(test_df[\"text\"]):\n",
    "\n",
    "    # format the prompt with the categories and the text\n",
    "    prompt = SYSTEM_PROMPT.format(categories=CATEGORIES, text=text)\n",
    "    \n",
    "    # generate the response from the model\n",
    "    response = model.generate(prompt)\n",
    "\n",
    "    # extract the generated text from the response\n",
    "    prediction = response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # append the prediction to the list of predictions\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.54      0.91      0.68       190\n",
      "    Sci/Tech       0.89      0.35      0.50       190\n",
      "      Sports       0.96      0.91      0.94       190\n",
      "       World       0.80      0.78      0.79       190\n",
      "\n",
      "    accuracy                           0.74       760\n",
      "   macro avg       0.80      0.74      0.73       760\n",
      "weighted avg       0.80      0.74      0.73       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df.label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model's performance shows varied strengths across categories. \n",
    "#The Business category has a high recall (0.91) but low precision (0.54), indicating it identifies many true instances but also includes numerous false positives. \n",
    "#The Sci/Tech category presents the opposite challenge, with high precision (0.89) but low recall (0.35), suggesting it misses many actual cases. \n",
    "#The Sports category performs well in both metrics, while the World category shows balanced performance.\n",
    "#Overall accuracy stands at 74%, with macro and weighted averages indicating better performance in categories with more instances.\n",
    "#To improve these results, hyperparameters such as learning rate, batch size, dropout rate, and model architecture could be adjusted. \n",
    "#Fine-tuning on more specific data and employing regularization techniques may also enhance classification, particularly in underperforming categories like Business and Sci/Tech.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.11 ('aiml25-ma2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "28f48453429376107ca9109bef082690e90d8ffd8f5b950883a8a6e2a12a44a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
