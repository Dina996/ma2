{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part I: Bag-of-Words Model\n",
    "\n",
    "Please see the description of the assignment in the README file (section 1) <br>\n",
    "**Guide notebook**: [guides/bow_guide.ipynb](guides/bow_guide.ipynb)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "* Note that you should report results using a classification report. \n",
    "\n",
    "* Also, remember to include some reflections on your results: Are there any hyperparameters that are particularly important?\n",
    "\n",
    "* You should follow the steps given in the `bow_guide` notebook\n",
    "\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (0.29.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from huggingface_hub) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from huggingface_hub) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages (from requests->huggingface_hub) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "# imports for the project\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "We can load this data directly from [Hugging Face Datasets](https://huggingface.co/docs/datasets/) - The HuggingFace Hub- into a Pandas DataFrame. Pretty neat!\n",
    "\n",
    "**Note**: This cell will download the dataset and keep it in memory. If you run this cell multiple times, it will download the dataset multiple times.\n",
    "\n",
    "You are welcome to increase the `frac` parameter to load more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 2) (7600, 2)\n",
      "Train shape: (1200, 2)\n",
      "Test shape: (760, 2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.76      0.74      0.75       190\n",
      "    Sci/Tech       0.76      0.78      0.77       190\n",
      "      Sports       0.87      0.88      0.87       190\n",
      "       World       0.83      0.82      0.82       190\n",
      "\n",
      "    accuracy                           0.81       760\n",
      "   macro avg       0.81      0.81      0.81       760\n",
      "weighted avg       0.81      0.81      0.81       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "\n",
    "train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])\n",
    "\n",
    "\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "# Definer label map\n",
    "label_map = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Sci/Tech'\n",
    "}\n",
    "\n",
    "def preprocess(df: pd.DataFrame, frac: float = 1e-2, label_map: dict[int, str] = label_map, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\" Preprocess the dataset \"\"\"\n",
    "    return (\n",
    "        df\n",
    "        .assign(label=lambda x: x['label'].map(label_map))  # Mapper labels\n",
    "        [lambda df: df['label'].isin(label_map.values())]  # Filtrerer labels\n",
    "        .groupby('label')[[\"text\", \"label\"]]  # Gruppering\n",
    "        .apply(lambda x: x.sample(frac=frac, random_state=seed))  # Stratificeret sampling\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# Preprocess data\n",
    "train_df = preprocess(train, frac=0.01)  # Sample 1% for training\n",
    "test_df = preprocess(test, frac=0.1)  # Sample 10% for testing\n",
    "\n",
    "# Ryd op i hukommelsen\n",
    "del train\n",
    "del test\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# Vælger tekst (X) og labels (y)\n",
    "X_train = train_df['text']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['label']\n",
    "\n",
    "# Opret BoW-model\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# Træn classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_bow, y_train)\n",
    "\n",
    "# Evaluer modellen\n",
    "y_pred = model.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedste hyperparametre: {'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "\n",
    "print(\"Bedste hyperparametre:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellen model præsterede med en samlet præcision på 81%, som fremgår af rapporten. \n",
    "# Sports-kategorien viste sig at være den bedst identificerede kategori, mens Business og World også præsterede tilfredsstillende. \n",
    "# Sci/Tech-kategorien havde dog lidt lavere præcision, hvilket antyder, at modellen muligvis har brug for flere eksempler eller bedre feature engineering for at forbedre identifikationen i denne kategori.\n",
    "\n",
    "# De væsentlige hyperparametre for denne model var:\n",
    "# Med en værdi af C på 1 sikrer vi en stærk balance mellem overfitting og underfitting.\n",
    "# Den valgte penalty er på 'l2'-regularisering hjalp med at minimere koefficienternes størrelse og havde en positiv indvirkning på det generelle resultat.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.11 ('aiml25-ma2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "28f48453429376107ca9109bef082690e90d8ffd8f5b950883a8a6e2a12a44a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
